# CA Lobby Database Strategy Recommendation

**Created**: October 28, 2025
**Updated for**: Monorepo architecture
**Purpose**: Recommend optimal database strategy using normalized CAL-ACCESS tables vs views
**Audience**: Database architects and developers
**Repository**: ca-lobby (monorepo)

---

## Executive Summary

**Recommendation**: **Use a HYBRID approach** - Start with raw normalized tables for comprehensive data, then create optimized views for the web application.

**Rationale**:
- Raw tables ensure ALL data points are available
- Views provide optimized query performance for web app
- Flexibility to add new data points without restructuring
- **No geographic filtering** - Statewide California lobbying data (Alameda was sample data for frontend testing only)
- **Direct BigQuery backend** - Web application queries BigQuery views via Flask API (no CSV exports in production)

---

## Repository Context

This project is structured as a **monorepo**:

```
ca-lobby/
├── backend/          # THIS recommendation - Data pipeline, BigQuery, API
├── frontend/         # React application consuming the backend API
└── docs/             # Shared documentation including this file
```

**This document focuses on the `backend/` implementation.**

---

## Current State Analysis

### What We're Using Now (Development/Testing Phase)

**Sample CSV Data** (Alameda County only - for frontend testing):
- `v_payments_alameda.csv` - Payment line items (9,699 records)
- `v_disclosures_alameda.csv` - Alameda-filtered disclosures (8,650 records - INCOMPLETE)
- `v_filers_alameda.csv` - Filer registry (49,459 records)

**Location**: `frontend/sample_data/` (in monorepo)

**Note**: Alameda County filtering was used ONLY for initial frontend development and testing with a manageable dataset (11 organizations, 3,357 transactions).

**Problem Identified in Sample Data**:
The Alameda-filtered disclosure view **excludes** disclosures filed by non-Alameda lobbying firms, even when those firms work for Alameda organizations. This causes:
- ❌ NULL `firm_name` fields
- ❌ NULL `date`, `from_date`, `thru_date` fields
- ❌ Non-functional lobbyist network feature

**Production Architecture**:
- ✅ No geographic filtering - Full statewide California lobbying data
- ✅ Direct BigQuery backend connection via Flask API
- ✅ Real-time query performance
- ✅ No CSV export/import pipeline

---

## Architecture: Development vs Production

### Development Architecture (Current - Alameda Sample Data)

```
BigQuery → CSV Export → frontend/sample_data/*.csv →
Python Scripts → frontend/src/data/*.json →
React Components → UI
```

**Characteristics**:
- Static CSV files (Alameda County only - 11 organizations)
- JSON files generated by Python scripts
- Frontend loads JSON files directly
- Limited to sample data for testing

**Limitations**:
- ❌ Data is stale (manual exports required)
- ❌ Alameda-only subset (missing 90% of CA organizations)
- ❌ NULL firm names break lobbyist network feature
- ❌ No dynamic search/filter capability

---

### Production Architecture (Target - Monorepo)

```
backend/                                    frontend/
  ├── BigQuery Tables                        ├── React App
  │   ↓                                      │
  ├── BigQuery Views   ←──┐                  │
  │   ↓                   │                  │
  ├── api/              Query                │
  │   ├── Flask API  ────┘                   │
  │   ├── routes/                            │
  │   │   ├── organizations.py  ←────── HTTP Request
  │   │   ├── lobbyists.py      ←────── HTTP Request
  │   │   └── activity.py       ←────── HTTP Request
  │   └── models/                            │
  │       └── bigquery_client.py             │
  │                                          │
  └── pipeline/                              │
      (ETL scripts)                          │
```

**Data Flow**:
1. **User searches** for organization in React frontend (frontend/src/)
2. **Frontend calls** Flask API: `GET /api/organizations?search=hospital`
3. **Flask backend queries** BigQuery view (backend/api/routes/organizations.py):
   `SELECT * FROM v_org_profiles_complete WHERE organization_name LIKE '%hospital%'`
4. **BigQuery returns** result set (filtered, paginated)
5. **Flask formats** as JSON and returns to frontend
6. **React renders** organization profiles

**Benefits**:
- ✅ **Real-time data** - Always current, no stale CSVs
- ✅ **Statewide coverage** - All California organizations (~10,000+)
- ✅ **Dynamic filtering** - User can filter by any field
- ✅ **Scalable** - Handles millions of records
- ✅ **No data synchronization** - Single source of truth
- ✅ **Pagination** - Load only what's needed
- ✅ **Caching** - Backend can cache frequent queries
- ✅ **Monorepo benefits** - Backend and frontend changes in one commit

---

## Normalized Database Structure

Based on backend/docs/California_Lobbying_Tables_Documentation.md, we have access to:

### Core Lobbying Tables

| Table | Purpose | Critical Fields | Records |
|-------|---------|----------------|---------|
| **CVR2_LOBBY_DISCLOSURE_CD** | Disclosure cover page | `filing_id`, `filer_id`, `period_start_date`, `period_end_date`, `firm_name`, `entity_code` | ~500K+ |
| **LPAY_CD** | Payment transactions | `filing_id`, `amount_paid`, `payee_name`, `payment_type` | ~100K+ |
| **LEMP_CD** | Employer-lobbyist relationships | `filing_id`, `employer_name`, `lobbyist_name`, `subcontracted` | ~50K+ |
| **LEXP_CD** | Lobbying expenditures | `filing_id`, `expense_type`, `amount`, `payee` | ~50K+ |
| **LOTH_CD** | Other payments | `filing_id`, `payment_amount`, `description` | ~200K+ |
| **CVR_REGISTRATION_CD** | Registration info | `filer_id`, `filer_name`, `address`, `business_class` | ~10K+ |

### Supporting Tables

| Table | Purpose | Why Important |
|-------|---------|---------------|
| **FILERS_CD** | Master filer registry | Links all entities across tables |
| **FILER_FILINGS_CD** | Filing index | Navigation between filers and filings |
| **TEXT_MEMO_CD** | Extended descriptions | Human-readable activity narratives |
| **LOOKUP_CODES_CD** | Code definitions | Decode form types, entity codes, payment types |
| **NAMES_CD** | Name information | Individual names for lobbyists |

**Location in Monorepo**: These tables exist in BigQuery and are managed by `backend/pipeline/`

---

## Recommended Database Strategy

### Phase 1: Import Full Normalized Tables

**Tables to Import** (Priority Order):

#### Essential (Import First):
1. **CVR2_LOBBY_DISCLOSURE_CD** - Disclosure cover pages
   - Contains: `firm_name`, `period_start_date`, `period_end_date`, `report_date`
   - Why: Fixes ALL missing data issues in current implementation

2. **LPAY_CD** - Payment transactions
   - Contains: Individual payment records with detail
   - Why: More granular than current payment data

3. **LEMP_CD** - Employer-lobbyist relationships
   - Contains: Links between organizations and their lobbyists
   - Why: Enables proper lobbyist network feature

4. **FILERS_CD** - Master filer registry
   - Contains: Complete entity information
   - Why: Foundation for all entity lookups

#### Important (Import Second):
5. **CVR_REGISTRATION_CD** - Registration information
6. **LEXP_CD** - Expenditures
7. **TEXT_MEMO_CD** - Text descriptions
8. **LOOKUP_CODES_CD** - Code definitions

#### Nice to Have (Import Third):
9. **LCCM_CD** - Campaign contributions
10. **LOTH_CD** - Other payments

**Implementation Location**: `backend/pipeline/upload_pipeline.py`

---

### Phase 2: Create Optimized Views

After importing raw tables, create views optimized for the Flask API.

**Location**: `backend/CREATE_ALL_VIEWS.sql` (already exists - 73 views)

#### View 1: Complete Organization Profile Data

```sql
CREATE OR REPLACE VIEW `ca-lobby.ca_lobby.v_org_profiles_complete` AS
SELECT
  -- Organization identification
  e.employer_full_name as organization_name,
  e.employer_id as filer_id,
  f.business_class as organization_type,
  f.city as organization_city,
  f.state as organization_state,
  f.zip4 as organization_zip,

  -- Disclosure information
  d.filing_id,
  d.amendment_id,
  d.period_start_date,
  d.period_end_date,
  d.report_date as filing_date,
  d.firm_name,
  d.form_type,
  d.entity_code,

  -- Payment details
  p.line_item,
  p.fees_amount,
  p.reimbursement_amount,
  p.advance_amount,
  (p.fees_amount + p.reimbursement_amount + p.advance_amount) as period_total,
  p.cumulative_total,

  -- Lobbyist information
  l.lobbyist_last_name,
  l.lobbyist_first_name,
  (l.lobbyist_first_name || ' ' || l.lobbyist_last_name) as lobbyist_name,

  -- Activity description
  t.text_description

FROM
  `ca-lobby.ca_lobby.LEMP_CD` e  -- Employer relationships
  INNER JOIN `ca-lobby.ca_lobby.CVR2_LOBBY_DISCLOSURE_CD` d ON e.filing_id = d.filing_id
  LEFT JOIN `ca-lobby.ca_lobby.LPAY_CD` p ON d.filing_id = p.filing_id
  LEFT JOIN `ca-lobby.ca_lobby.NAMES_CD` l ON e.lobbyist_id = l.filer_id
  LEFT JOIN `ca-lobby.ca_lobby.CVR_REGISTRATION_CD` f ON e.employer_id = f.filer_id
  LEFT JOIN `ca-lobby.ca_lobby.TEXT_MEMO_CD` t ON d.filing_id = t.filing_id

-- NO WHERE CLAUSE - Returns ALL California lobbying organizations
-- Flask API handles filtering based on user search criteria

ORDER BY d.period_start_date DESC;
```

**Flask API Usage** (`backend/api/routes/organizations.py`):
```python
@app.route('/api/organizations', methods=['GET'])
def get_organizations():
    search = request.args.get('search', '')
    city = request.args.get('city', '')
    limit = min(int(request.args.get('limit', 100)), 1000)

    query = """
        SELECT * FROM `ca-lobby.ca_lobby.v_org_profiles_complete`
        WHERE (@search = '' OR LOWER(organization_name) LIKE CONCAT('%', LOWER(@search), '%'))
        AND (@city = '' OR LOWER(organization_city) = LOWER(@city))
        ORDER BY period_start_date DESC
        LIMIT @limit
    """

    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("search", "STRING", search),
            bigquery.ScalarQueryParameter("city", "STRING", city),
            bigquery.ScalarQueryParameter("limit", "INT64", limit),
        ]
    )

    results = bigquery_client.query(query, job_config=job_config).result()
    return jsonify({'data': [dict(row) for row in results]})
```

**Key Features**:
- **No geographic filtering** - Returns all California data
- **Joins by EMPLOYER** (the organization), not FILER (lobbying firm)
- **Includes location fields** (city, state, zip) for API filtering
- **Flask API handles filtering** based on query parameters

---

#### View 2: Lobbyist Network Data

```sql
CREATE OR REPLACE VIEW `ca-lobby.ca_lobby.v_lobbyist_network` AS
SELECT
  e.employer_full_name as organization_name,
  e.employer_id as filer_id,
  d.firm_name as lobbying_firm,
  d.filer_id as firm_filer_id,
  (l.lobbyist_first_name || ' ' || l.lobbyist_last_name) as lobbyist_name,
  l.filer_id as lobbyist_filer_id,
  COUNT(DISTINCT d.filing_id) as filing_count,
  SUM(p.fees_amount) as total_fees_paid,
  SUM(p.reimbursement_amount) as total_reimbursements,
  SUM(p.advance_amount) as total_advances,
  MIN(d.period_start_date) as first_activity,
  MAX(d.period_end_date) as last_activity,

  -- Relationship type
  CASE
    WHEN e.subcontracted = 'Y' THEN 'Subcontracted'
    ELSE 'Direct Hire'
  END as relationship_type

FROM
  `ca-lobby.ca_lobby.LEMP_CD` e
  INNER JOIN `ca-lobby.ca_lobby.CVR2_LOBBY_DISCLOSURE_CD` d ON e.filing_id = d.filing_id
  LEFT JOIN `ca-lobby.ca_lobby.LPAY_CD` p ON d.filing_id = p.filing_id
  LEFT JOIN `ca-lobby.ca_lobby.NAMES_CD` l ON e.lobbyist_id = l.filer_id

-- NO WHERE CLAUSE - Flask API filters by organization_id
GROUP BY
  e.employer_full_name,
  e.employer_id,
  d.firm_name,
  d.filer_id,
  lobbyist_name,
  l.filer_id,
  e.subcontracted

ORDER BY
  e.employer_full_name,
  total_fees_paid DESC;
```

**Flask API Usage** (`backend/api/routes/lobbyists.py`):
```python
@app.route('/api/lobbyists/<filer_id>', methods=['GET'])
def get_lobbyist_network(filer_id):
    query = """
        SELECT * FROM `ca-lobby.ca_lobby.v_lobbyist_network`
        WHERE filer_id = @filer_id
        ORDER BY total_fees_paid DESC
    """

    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("filer_id", "STRING", filer_id),
        ]
    )

    results = bigquery_client.query(query, job_config=job_config).result()
    return jsonify({'data': [dict(row) for row in results]})
```

**Frontend Usage** (`frontend/src/components/LobbyistNetwork.js`):
```javascript
const fetchLobbyistNetwork = async (filerId) => {
  const response = await fetch(`${API_URL}/api/lobbyists/${filerId}`);
  const data = await response.json();
  setLobbyistData(data.data);
};
```

---

#### View 3: Activity Timeline Data

```sql
CREATE OR REPLACE VIEW `ca-lobby.ca_lobby.v_activity_timeline` AS
SELECT
  e.employer_full_name as organization_name,
  e.employer_id as filer_id,
  d.filing_id,
  d.amendment_id,
  d.period_start_date,
  d.period_end_date,
  d.report_date,
  d.firm_name,
  d.form_type,
  d.entity_code,

  -- Aggregated payment info
  SUM(p.fees_amount) as total_fees,
  SUM(p.reimbursement_amount) as total_reimbursements,
  SUM(p.advance_amount) as total_advances,
  SUM(p.fees_amount + p.reimbursement_amount + p.advance_amount) as total_payments,
  COUNT(p.line_item) as payment_line_items,

  -- Activity description
  MAX(t.text_description) as activity_description

FROM
  `ca-lobby.ca_lobby.LEMP_CD` e
  INNER JOIN `ca-lobby.ca_lobby.CVR2_LOBBY_DISCLOSURE_CD` d ON e.filing_id = d.filing_id
  LEFT JOIN `ca-lobby.ca_lobby.LPAY_CD` p ON d.filing_id = p.filing_id
  LEFT JOIN `ca-lobby.ca_lobby.TEXT_MEMO_CD` t ON d.filing_id = t.filing_id

WHERE
  -- Only get latest amendments
  d.amendment_id = (
    SELECT MAX(amendment_id)
    FROM `ca-lobby.ca_lobby.CVR2_LOBBY_DISCLOSURE_CD` d2
    WHERE d2.filing_id = d.filing_id
  )

GROUP BY
  e.employer_full_name,
  e.employer_id,
  d.filing_id,
  d.amendment_id,
  d.period_start_date,
  d.period_end_date,
  d.report_date,
  d.firm_name,
  d.form_type,
  d.entity_code

ORDER BY
  d.period_start_date DESC;
```

---

#### View 4: Expenditure Categories

```sql
CREATE OR REPLACE VIEW `ca-lobby.ca_lobby.v_expenditure_categories` AS
SELECT
  e.employer_full_name as organization_name,
  e.employer_id as filer_id,
  d.filing_id,
  d.period_start_date,
  d.period_end_date,

  -- Expenditure breakdown
  exp.expense_type,
  lc.code_description as expense_type_description,
  SUM(exp.amount) as total_amount,
  COUNT(*) as expense_count,
  AVG(exp.amount) as average_amount,

  -- Payee information
  exp.payee_name,
  exp.payee_city,
  exp.payee_state

FROM
  `ca-lobby.ca_lobby.LEMP_CD` e
  INNER JOIN `ca-lobby.ca_lobby.CVR2_LOBBY_DISCLOSURE_CD` d ON e.filing_id = d.filing_id
  INNER JOIN `ca-lobby.ca_lobby.LEXP_CD` exp ON d.filing_id = exp.filing_id
  LEFT JOIN `ca-lobby.ca_lobby.LOOKUP_CODES_CD` lc ON exp.expense_type = lc.code

GROUP BY
  e.employer_full_name,
  e.employer_id,
  d.filing_id,
  d.period_start_date,
  d.period_end_date,
  exp.expense_type,
  lc.code_description,
  exp.payee_name,
  exp.payee_city,
  exp.payee_state

ORDER BY
  e.employer_full_name,
  d.period_start_date DESC,
  total_amount DESC;
```

---

## Performance Considerations

### Query Cost Management

These views will scan large tables on every query. To prevent excessive costs:

**1. Always use WHERE clauses in API queries:**
```python
# GOOD: Scans minimal data
query = """
    SELECT * FROM v_org_profiles_complete
    WHERE organization_name = @name
    AND period_start_date >= @start_date
"""

# BAD: Scans entire table (potentially $10+ per query)
query = "SELECT * FROM v_org_profiles_complete"
```

**2. Implement table partitioning:**
```sql
-- Partition CVR2_LOBBY_DISCLOSURE_CD by period_start_date
ALTER TABLE `ca-lobby.ca_lobby.CVR2_LOBBY_DISCLOSURE_CD`
SET OPTIONS (
  partition_expiration_days = NULL,
  require_partition_filter = true
);
```

**3. Use materialized views for frequently accessed patterns:**
- Current year data
- Top 100 organizations by spending
- Recent filings (last 90 days)

**4. Estimated Query Costs:**
- Without optimization: $0.50 - $2.00 per full scan
- With partitioning and filters: $0.01 - $0.10 per query

**More details**: See `backend/docs/BigQuery_Optimization_Plan.md`

---

## Implementation Recommendation

### Immediate Actions (Week 1)

**Location**: `backend/`

1. **Verify BigQuery Tables** (if not already imported):
   ```bash
   cd backend
   python run_download.py
   python run_upload_pipeline.py
   ```

2. **Create Optimized Views in BigQuery**:
   ```bash
   bq query --use_legacy_sql=false < backend/CREATE_ALL_VIEWS.sql
   ```

3. **Set up Flask API skeleton**:
   ```bash
   cd backend
   mkdir -p api/routes api/models
   touch api/app.py api/config.py
   touch api/routes/organizations.py
   touch api/routes/lobbyists.py
   touch api/models/bigquery_client.py
   ```

---

### Short-term Enhancements (Week 2-3)

**Location**: `backend/api/`

4. **Implement Flask API Endpoints**:

**backend/api/app.py**:
```python
from flask import Flask, jsonify
from flask_cors import CORS
from routes import organizations, lobbyists, activity

app = Flask(__name__)
CORS(app)  # Allow frontend to call API

# Register blueprints
app.register_blueprint(organizations.bp)
app.register_blueprint(lobbyists.bp)
app.register_blueprint(activity.bp)

@app.route('/health')
def health_check():
    return jsonify({'status': 'healthy'})

if __name__ == '__main__':
    app.run(debug=True, port=5000)
```

**backend/api/routes/organizations.py**:
```python
from flask import Blueprint, request, jsonify
from models.bigquery_client import BigQueryClient

bp = Blueprint('organizations', __name__, url_prefix='/api/organizations')
client = BigQueryClient()

@bp.route('', methods=['GET'])
def search_organizations():
    """Search organizations by name, city, or other criteria"""
    search = request.args.get('search', '')
    city = request.args.get('city', '')
    limit = min(int(request.args.get('limit', 100)), 1000)
    offset = int(request.args.get('offset', 0))

    query = """
        SELECT *
        FROM `ca-lobby.ca_lobby.v_org_profiles_complete`
        WHERE 1=1
        AND (@search = '' OR LOWER(organization_name) LIKE CONCAT('%', LOWER(@search), '%'))
        AND (@city = '' OR LOWER(organization_city) = LOWER(@city))
        ORDER BY period_start_date DESC
        LIMIT @limit
        OFFSET @offset
    """

    results = client.execute_query(query, {
        'search': search,
        'city': city,
        'limit': limit,
        'offset': offset
    })

    return jsonify({
        'data': results,
        'count': len(results),
        'limit': limit,
        'offset': offset
    })

@bp.route('/<filer_id>', methods=['GET'])
def get_organization_detail(filer_id):
    """Get detailed profile for a specific organization"""
    query = """
        SELECT *
        FROM `ca-lobby.ca_lobby.v_org_profiles_complete`
        WHERE filer_id = @filer_id
    """

    results = client.execute_query(query, {'filer_id': filer_id})

    if not results:
        return jsonify({'error': 'Organization not found'}), 404

    return jsonify({'data': results[0]})
```

**backend/api/models/bigquery_client.py**:
```python
from google.cloud import bigquery
import os

class BigQueryClient:
    def __init__(self):
        self.client = bigquery.Client()

    def execute_query(self, query, params=None):
        """Execute a parameterized BigQuery query"""
        if params:
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter(k, self._infer_type(v), v)
                    for k, v in params.items()
                ]
            )
        else:
            job_config = None

        query_job = self.client.query(query, job_config=job_config)
        results = query_job.result()

        return [dict(row) for row in results]

    def _infer_type(self, value):
        """Infer BigQuery parameter type from Python value"""
        if isinstance(value, int):
            return "INT64"
        elif isinstance(value, float):
            return "FLOAT64"
        elif isinstance(value, bool):
            return "BOOL"
        else:
            return "STRING"
```

5. **Update Frontend to Use API**:

**Location**: `frontend/src/services/api.js`

```javascript
const API_URL = process.env.REACT_APP_API_URL || 'http://localhost:5000/api';

export const searchOrganizations = async (searchTerm, filters = {}) => {
  const params = new URLSearchParams({
    search: searchTerm,
    ...filters,
    limit: filters.limit || 100,
    offset: filters.offset || 0
  });

  const response = await fetch(`${API_URL}/organizations?${params}`);
  if (!response.ok) {
    throw new Error('Failed to fetch organizations');
  }

  return response.json();
};

export const getOrganizationDetail = async (filerId) => {
  const response = await fetch(`${API_URL}/organizations/${filerId}`);
  if (!response.ok) {
    throw new Error('Failed to fetch organization details');
  }

  return response.json();
};

export const getLobbyistNetwork = async (filerId) => {
  const response = await fetch(`${API_URL}/lobbyists/${filerId}`);
  if (!response.ok) {
    throw new Error('Failed to fetch lobbyist network');
  }

  return response.json();
};
```

**frontend/src/components/OrganizationSearch.js**:
```javascript
import React, { useState, useEffect } from 'react';
import { searchOrganizations } from '../services/api';

function OrganizationSearch() {
  const [searchTerm, setSearchTerm] = useState('');
  const [results, setResults] = useState([]);
  const [loading, setLoading] = useState(false);

  const handleSearch = async () => {
    setLoading(true);
    try {
      const data = await searchOrganizations(searchTerm);
      setResults(data.data);
    } catch (error) {
      console.error('Search failed:', error);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div>
      <input
        type="text"
        value={searchTerm}
        onChange={(e) => setSearchTerm(e.target.value)}
        placeholder="Search organizations..."
      />
      <button onClick={handleSearch} disabled={loading}>
        {loading ? 'Searching...' : 'Search'}
      </button>

      <div>
        {results.map(org => (
          <OrganizationCard key={org.filer_id} data={org} />
        ))}
      </div>
    </div>
  );
}
```

6. **Deploy Flask API** (Cloud Run recommended):
   ```bash
   cd backend
   gcloud run deploy ca-lobby-api \
     --source . \
     --region us-west1 \
     --allow-unauthenticated
   ```

7. **Update Frontend Environment Variables**:
   ```bash
   # frontend/.env.production
   REACT_APP_API_URL=https://ca-lobby-api-xxx.run.app/api
   ```

---

### Long-term Features (Month 2+)

8. **Advanced Analytics**:
   - Campaign contribution tracking (LCCM_CD)
   - Subcontractor network visualization
   - Agency targeting analysis
   - Industry comparison tools

9. **Enhanced Search**:
   - Search by lobbyist name
   - Filter by firm
   - Date range queries
   - Expense type filtering

10. **Compliance Dashboard**:
    - Ethics training status
    - Filing timeliness
    - Amendment tracking

---

## Migration Plan with Monorepo Context

### Phase 1: Backend View Creation (backend/)

- [x] Identified NULL fields (firm names, dates)
- [x] Documented root cause (filtered views)
- [ ] Create production views in BigQuery
  ```bash
  cd backend
  bq query --use_legacy_sql=false < CREATE_ALL_VIEWS.sql
  ```

### Phase 2: Backend API Development (backend/api/)

- [ ] Set up Flask application structure
- [ ] Implement BigQuery client wrapper
- [ ] Create organization endpoints
- [ ] Create lobbyist endpoints
- [ ] Create activity endpoints
- [ ] Add caching layer (Redis or in-memory)
- [ ] Deploy to Cloud Run

### Phase 3: Frontend Integration (frontend/)

- [ ] Create API client service (frontend/src/services/api.js)
- [ ] Update components to use API instead of static JSON
- [ ] Remove static data files (frontend/src/data/*.json)
- [ ] Add loading states and error handling
- [ ] Test with production data
- [ ] Deploy to Vercel

### Phase 4: Testing & Optimization

- [ ] End-to-end testing across monorepo
- [ ] Performance testing (query times)
- [ ] Cost monitoring (BigQuery costs)
- [ ] Implement BigQuery optimizations (partitioning, clustering)

---

## Cost Analysis

### Storage Costs
- Raw tables: ~100 GB × $0.02/GB = **$2.00/month**
- Views: $0 (virtual, no storage)
- **Total Storage: ~$2/month**

### Query Costs (Without Optimization)
- Average query: Scans 5-10 GB
- Cost per TB: $6.25
- Estimated queries: 100/day
- **Estimated Query Costs: $50-100/month** (unoptimized)

### Query Costs (With Optimization)
- Average query: Scans 50-500 MB (90-98% reduction via partitioning/clustering)
- **Optimized Query Costs: $2.80-5/month** (94% reduction)

### Infrastructure Costs
- BigQuery (optimized): $5-10/month
- Cloud Run (Flask API): $5-10/month
- Vercel (frontend): Free tier
- **Total: ~$15/month**

### ROI
- Optimization pays for itself in first month
- Annual savings: ~$858 vs unoptimized approach

---

## Monorepo Benefits for This Strategy

### Single Commit = Full Feature

**Example: Adding Lobbyist Network Feature**

```bash
git checkout -b feature/lobbyist-network

# Backend: Create view
echo "CREATE VIEW v_lobbyist_network..." > backend/new_view.sql

# Backend: Add API endpoint
vim backend/api/routes/lobbyists.py

# Frontend: Add component
vim frontend/src/components/LobbyistNetwork.js

# Documentation: Update API docs
vim docs/API_DOCUMENTATION.md

# Single commit with everything
git add .
git commit -m "feat: add lobbyist network feature

- Add v_lobbyist_network BigQuery view (backend/)
- Add /api/lobbyists/:id endpoint (backend/api/)
- Add LobbyistNetwork component (frontend/)
- Update API documentation (docs/)"

git push origin feature/lobbyist-network
```

**Benefits**:
- ✅ All changes in one PR - easy to review
- ✅ No coordination between repos needed
- ✅ Documentation updated in same commit
- ✅ No version mismatch possible
- ✅ Can test full stack locally before pushing

---

## Conclusion

**Recommended Approach**: Import full normalized tables + Create optimized views + Build Flask API (monorepo structure)

**Why**:
1. **Ensures ALL data points available** - No more NULL fields or missing data
2. **Fixes current issues** - Lobbyist network and timeline features will work
3. **Enables future features** - Expense analysis, agency tracking, etc.
4. **Minimal cost** - ~1 week setup time, $15/month infrastructure
5. **Best practice** - Normalized tables with view abstraction is industry standard
6. **Monorepo benefits** - Backend and frontend changes coordinated in single commits

**Next Step**:
1. Create BigQuery views: `cd backend && bq query < CREATE_ALL_VIEWS.sql`
2. Build Flask API in `backend/api/`
3. Update frontend to consume API in `frontend/src/`

---

**Document Status**: Ready for Implementation
**Estimated ROI**: High (fixes critical data gaps, enables multiple new features)
**Risk Level**: Low (non-breaking change, existing features continue working)
**Monorepo**: Simplifies implementation and coordination
